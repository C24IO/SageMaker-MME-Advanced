{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Multi-Model Endpoints using your own algorithm container\n",
    "With [Amazon SageMaker multi-model endpoints](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html), customers can create an endpoint that seamlessly hosts up to thousands of models. These endpoints are well suited to use cases where any one of a large number of models, which can be served from a common inference container, needs to be invokable on-demand and where it is acceptable for infrequently invoked models to incur some additional latency. For applications which require consistently low inference latency, a traditional endpoint is still the best choice.\n",
    "\n",
    "At a high level, Amazon SageMaker manages the loading and unloading of models for a multi-model endpoint, as they are needed. When an invocation request is made for a particular model, Amazon SageMaker routes the request to an instance assigned to that model, downloads the model artifacts from S3 onto that instance, and initiates loading of the model into the memory of the container. As soon as the loading is complete, Amazon SageMaker performs the requested invocation and returns the result. If the model is already loaded in memory on the selected instance, the downloading and loading steps are skipped and the invocation is performed immediately.\n",
    "\n",
    "For the inference container to serve multiple models in a multi-model endpoint, it must implement [additional APIs](https://docs.aws.amazon.com/sagemaker/latest/dg/build-multi-model-build-container.html) in order to load, list, get, unload and invoke specific models. This notebook demonstrates how to build your own inference container that implements these APIs.\n",
    "\n",
    "---\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. [Introduction to Multi Model Server (MMS)](#Introduction-to-Multi-Model-Server-(MMS))\n",
    "  1. [Handling Out Of Memory conditions](#Handling-Out-Of-Memory-conditions)\n",
    "  1. [SageMaker Inference Toolkit](#SageMaker-Inference-Toolkit)\n",
    "1. [Building and registering a container using MMS](#Building-and-registering-a-container-using-MMS)\n",
    "1. [Set up the environment](#Set-up-the-environment)\n",
    "1. [Upload model artifacts to S3](#Upload-model-artifacts-to-S3)\n",
    "1. [Create a multi-model endpoint](#Create-a-multi-model-endpoint)\n",
    "  1. [Import models into hosting](#Import-models-into-hosting)\n",
    "  1. [Create endpoint configuration](#Create-endpoint-configuration)\n",
    "  1. [Create endpoint](#Create-endpoint)\n",
    "1. [Invoke models](#Invoke-models)\n",
    "  1. [Add models to the endpoint](#Add-models-to-the-endpoint)\n",
    "  1. [Updating a model](#Updating-a-model)\n",
    "1. [(Optional) Delete the hosting resources](#(Optional)-Delete-the-hosting-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Multi Model Server (MMS)\n",
    "\n",
    "[Multi Model Server](https://github.com/awslabs/multi-model-server) is an open source framework for serving machine learning models. It provides the HTTP frontend and model management capabilities required by multi-model endpoints to host multiple models within a single container, load models into and unload models out of the container dynamically, and performing inference on a specified loaded model.\n",
    "\n",
    "MMS supports a pluggable custom backend handler where you can implement your own algorithm. This example uses a handler that supports loading and inference for MXNet models, which we will inspect below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "ModelHandler defines an example model handler for load and inference requests for MXNet CPU models\n",
      "\"\"\"\n",
      "from collections import namedtuple\n",
      "import glob\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import re\n",
      "\n",
      "import mxnet as mx\n",
      "import numpy as np\n",
      "\n",
      "class ModelHandler(object):\n",
      "    \"\"\"\n",
      "    A sample Model handler implementation.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self):\n",
      "        self.initialized = False\n",
      "        self.mx_model = None\n",
      "        self.shapes = None\n",
      "\n",
      "    def get_model_files_prefix(self, model_dir):\n",
      "        \"\"\"\n",
      "        Get the model prefix name for the model artifacts (symbol and parameter file).\n",
      "        This assume model artifact directory contains a symbol file, parameter file, \n",
      "        model shapes file and a synset file defining the labels\n",
      "\n",
      "        :param model_dir: Path to the directory with model artifacts\n",
      "        :return: prefix string for model artifact files\n",
      "        \"\"\"\n",
      "        sym_file_suffix = \"-symbol.json\"\n",
      "        checkpoint_prefix_regex = \"{}/*{}\".format(model_dir, sym_file_suffix) # Ex output: /opt/ml/models/resnet-18/model/*-symbol.json\n",
      "        checkpoint_prefix_filename = glob.glob(checkpoint_prefix_regex)[0] # Ex output: /opt/ml/models/resnet-18/model/resnet18-symbol.json\n",
      "        checkpoint_prefix = os.path.basename(checkpoint_prefix_filename).split(sym_file_suffix)[0] # Ex output: resnet18\n",
      "        logging.info(\"Prefix for the model artifacts: {}\".format(checkpoint_prefix))\n",
      "        return checkpoint_prefix\n",
      "\n",
      "    def get_input_data_shapes(self, model_dir, checkpoint_prefix):\n",
      "        \"\"\"\n",
      "        Get the model input data shapes and return the list\n",
      "\n",
      "        :param model_dir: Path to the directory with model artifacts\n",
      "        :param checkpoint_prefix: Model files prefix name\n",
      "        :return: prefix string for model artifact files\n",
      "        \"\"\"\n",
      "        shapes_file_path = os.path.join(model_dir, \"{}-{}\".format(checkpoint_prefix, \"shapes.json\"))\n",
      "        if not os.path.isfile(shapes_file_path):\n",
      "            raise RuntimeError(\"Missing {} file.\".format(shapes_file_path))\n",
      "\n",
      "        with open(shapes_file_path) as f:\n",
      "            self.shapes = json.load(f)\n",
      "\n",
      "        data_shapes = []\n",
      "\n",
      "        for input_data in self.shapes:\n",
      "            data_name = input_data[\"name\"]\n",
      "            data_shape = input_data[\"shape\"]\n",
      "            data_shapes.append((data_name, tuple(data_shape)))\n",
      "\n",
      "        return data_shapes\n",
      "\n",
      "    def initialize(self, context):\n",
      "        \"\"\"\n",
      "        Initialize model. This will be called during model loading time\n",
      "        :param context: Initial context contains model server system properties.\n",
      "        :return:\n",
      "        \"\"\"\n",
      "        self.initialized = True\n",
      "        properties = context.system_properties\n",
      "        # Contains the url parameter passed to the load request\n",
      "        model_dir = properties.get(\"model_dir\") \n",
      "        gpu_id = properties.get(\"gpu_id\")\n",
      "\n",
      "        checkpoint_prefix = self.get_model_files_prefix(model_dir)\n",
      "\n",
      "        # Read the model input data shapes\n",
      "        data_shapes = self.get_input_data_shapes(model_dir, checkpoint_prefix)\n",
      "         \n",
      "        # Load MXNet model\n",
      "        try:\n",
      "            ctx = mx.cpu() # Set the context on CPU\n",
      "            sym, arg_params, aux_params = mx.model.load_checkpoint(checkpoint_prefix, 0)  # epoch set to 0\n",
      "            self.mx_model = mx.mod.Module(symbol=sym, context=ctx, label_names=None)\n",
      "            self.mx_model.bind(for_training=False, data_shapes=data_shapes, \n",
      "                   label_shapes=self.mx_model._label_shapes)\n",
      "            self.mx_model.set_params(arg_params, aux_params, allow_missing=True)\n",
      "            with open(\"synset.txt\", 'r') as f:\n",
      "                self.labels = [l.rstrip() for l in f]\n",
      "        except (mx.base.MXNetError, RuntimeError) as memerr:\n",
      "            if re.search('Failed to allocate (.*) Memory', str(memerr), re.IGNORECASE):\n",
      "                logging.error(\"Memory allocation exception: {}\".format(memerr))\n",
      "                raise MemoryError\n",
      "            raise           \n",
      "\n",
      "    def preprocess(self, request):\n",
      "        \"\"\"\n",
      "        Transform raw input into model input data.\n",
      "        :param request: list of raw requests\n",
      "        :return: list of preprocessed model input data\n",
      "        \"\"\"\n",
      "        # Take the input data and pre-process it make it inference ready\n",
      "\n",
      "        img_list = []\n",
      "        for idx, data in enumerate(request):\n",
      "            # Read the bytearray of the image from the input\n",
      "            img_arr = data.get('body')  \n",
      "\n",
      "            # Input image is in bytearray, convert it to MXNet NDArray\n",
      "            img = mx.img.imdecode(img_arr) \n",
      "            if img is None:\n",
      "                return None\n",
      "\n",
      "            # convert into format (batch, RGB, width, height)\n",
      "            img = mx.image.imresize(img, 224, 224) # resize\n",
      "            img = img.transpose((2, 0, 1)) # Channel first\n",
      "            img = img.expand_dims(axis=0) # batchify\n",
      "            img_list.append(img)\n",
      "\n",
      "        return img_list\n",
      "\n",
      "    def inference(self, model_input):\n",
      "        \"\"\"\n",
      "        Internal inference methods\n",
      "        :param model_input: transformed model input data list\n",
      "        :return: list of inference output in NDArray\n",
      "        \"\"\"\n",
      "        # Do some inference call to engine here and return output\n",
      "        Batch = namedtuple('Batch', ['data'])\n",
      "        self.mx_model.forward(Batch(model_input))\n",
      "        prob = self.mx_model.get_outputs()[0].asnumpy()\n",
      "        return prob\n",
      "\n",
      "    def postprocess(self, inference_output):\n",
      "        \"\"\"\n",
      "        Return predict result in as list.\n",
      "        :param inference_output: list of inference output\n",
      "        :return: list of predict results\n",
      "        \"\"\"\n",
      "        # Take output from network and post-process to desired format\n",
      "        prob = np.squeeze(inference_output)\n",
      "        a = np.argsort(prob)[::-1]\n",
      "        return [['probability=%f, class=%s' %(prob[i], self.labels[i]) for i in a[0:5]]]\n",
      "        \n",
      "    def handle(self, data, context):\n",
      "        \"\"\"\n",
      "        Call preprocess, inference and post-process functions\n",
      "        :param data: input data\n",
      "        :param context: mms context\n",
      "        \"\"\"\n",
      "        \n",
      "        model_input = self.preprocess(data)\n",
      "        model_out = self.inference(model_input)\n",
      "        return self.postprocess(model_out)\n",
      "\n",
      "_service = ModelHandler()\n",
      "\n",
      "\n",
      "def handle(data, context):\n",
      "    if not _service.initialized:\n",
      "        _service.initialize(context)\n",
      "\n",
      "    if data is None:\n",
      "        return None\n",
      "\n",
      "    return _service.handle(data, context)\n"
     ]
    }
   ],
   "source": [
    "!cat container/model_handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of note are the `handle(data, context)` and `initialize(self, context)` methods.\n",
    "\n",
    "The `initialize` method will be called when a model is loaded into memory. In this example, it loads the model artifacts at `model_dir` into MXNet.\n",
    "\n",
    "The `handle` method will be called when invoking the model. In this example, it validates the input payload and then forwards the input to MXNet, returning the output.\n",
    "\n",
    "This handler class is instantiated for every model loaded into the container, so state in the handler is not shared across models.\n",
    "\n",
    "### Handling Out Of Memory conditions\n",
    "If MXNet fails to load the model due to lack of memory, a `MemoryError` is raised. Any time a model cannot be loaded due to lack of memory or any other resource constraint, a `MemoryError` must be raised. MMS will interpret the `MemoryError`, and return a 507 HTTP status code to SageMaker, where SageMaker will initiate unloading unused models to reclaim resources so the requested model can be loaded.\n",
    "\n",
    "### SageMaker Inference Toolkit\n",
    "MMS supports [various settings](https://github.com/awslabs/multi-model-server/blob/master/docker/advanced_settings.md#description-of-config-file-settings) for the frontend server it starts.\n",
    "\n",
    "[SageMaker Inference Toolkit](https://github.com/aws/sagemaker-inference-toolkit) is a library that bootstraps MMS in a way that is compatible with SageMaker multi-model endpoints, while still allowing you to tweak important performance parameters, such as the number of workers per model. The inference container in this example uses the Inference Toolkit to start MMS which can be seen in the __`container/dockerd-entrypoint.py`__ file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and registering a container using MMS\n",
    "\n",
    "The shell script below will build a Docker image which uses MMS as the front end (configured through SageMaker Inference Toolkit), and `container/model_handler.py` that we inspected above as the backend handler. It will then upload the image to an ECR repository in your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "sha256:9ffc6d6b4deb792fa55c40ffbac3a2333f3b9e6999a05f559a4b2489fa74281e\n",
      "The push refers to repository [111652037296.dkr.ecr.us-east-1.amazonaws.com/demo-sagemaker-multimodel]\n",
      "b5441d882d92: Preparing\n",
      "92bc0dc4073d: Preparing\n",
      "110fd74032f5: Preparing\n",
      "c650a8ce6123: Preparing\n",
      "4d49009b2165: Preparing\n",
      "feb7b9f6a5a6: Preparing\n",
      "66142d0e64d8: Preparing\n",
      "a78bcfb6fb4e: Preparing\n",
      "64d2e4aaa54c: Preparing\n",
      "0d3833376c2f: Preparing\n",
      "4a048ea09024: Preparing\n",
      "b592b5433bbf: Preparing\n",
      "feb7b9f6a5a6: Waiting\n",
      "66142d0e64d8: Waiting\n",
      "a78bcfb6fb4e: Waiting\n",
      "64d2e4aaa54c: Waiting\n",
      "0d3833376c2f: Waiting\n",
      "4a048ea09024: Waiting\n",
      "b592b5433bbf: Waiting\n",
      "b5441d882d92: Pushed\n",
      "110fd74032f5: Pushed\n",
      "c650a8ce6123: Pushed\n",
      "92bc0dc4073d: Pushed\n",
      "66142d0e64d8: Pushed\n",
      "64d2e4aaa54c: Pushed\n",
      "feb7b9f6a5a6: Pushed\n",
      "4a048ea09024: Pushed\n",
      "0d3833376c2f: Pushed\n",
      "b592b5433bbf: Pushed\n",
      "4d49009b2165: Pushed\n",
      "a78bcfb6fb4e: Pushed\n",
      "latest: digest: sha256:28c896b1ec9798f0f7440a485a9758144584509c56bba94c3fe18e2931b157cd size: 2821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=demo-sagemaker-multimodel\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "Define the S3 bucket and prefix where the model artifacts that will be invokable by your multi-model endpoint will be located.\n",
    "\n",
    "Also define the IAM role that will give SageMaker access to the model artifacts and ECR image that was created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU awscli boto3 sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "runtime_sm_client = boto3.client(service_name='sagemaker-runtime')\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket = 'sagemaker-{}-{}'.format(region, account_id)\n",
    "prefix = 'demo-multimodel-endpoint'\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model artifacts to S3\n",
    "In this example we will use pre-trained ResNet 18 and ResNet 152 models, both trained on the ImageNet datset. First we will download the models from MXNet's model zoo, and then upload them to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "model_path = 'http://data.mxnet.io/models/imagenet/'\n",
    "\n",
    "mx.test_utils.download(model_path+'resnet/18-layers/resnet-18-0000.params', None, 'data/resnet_18')\n",
    "mx.test_utils.download(model_path+'resnet/18-layers/resnet-18-symbol.json', None, 'data/resnet_18')\n",
    "mx.test_utils.download(model_path+'synset.txt', None, 'data/resnet_18')\n",
    "\n",
    "with open('data/resnet_18/resnet-18-shapes.json', 'w') as file:\n",
    "    file.write('[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]')\n",
    "    \n",
    "with tarfile.open('data/resnet_18.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('data/resnet_18', arcname='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.test_utils.download(model_path+'resnet/152-layers/resnet-152-0000.params', None, 'data/resnet_152')\n",
    "mx.test_utils.download(model_path+'resnet/152-layers/resnet-152-symbol.json', None, 'data/resnet_152')\n",
    "mx.test_utils.download(model_path+'synset.txt', None, 'data/resnet_152')\n",
    "\n",
    "with open('data/resnet_152/resnet-152-shapes.json', 'w') as file:\n",
    "    file.write('[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]')\n",
    "    \n",
    "with tarfile.open('data/resnet_152.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('data/resnet_152', arcname='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.client import ClientError\n",
    "import os\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    s3.meta.client.head_bucket(Bucket=bucket)\n",
    "except ClientError:\n",
    "    s3.create_bucket(Bucket=bucket,\n",
    "                     CreateBucketConfiguration={\n",
    "                         'LocationConstraint': region\n",
    "                     })\n",
    "\n",
    "models = {'resnet_18.tar.gz', 'resnet_152.tar.gz'}\n",
    "\n",
    "for model in models:\n",
    "    key = os.path.join(prefix, model)\n",
    "    with open('data/'+model, 'rb') as file_obj:\n",
    "        s3.Bucket(bucket).Object(key).upload_fileobj(file_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a multi-model endpoint\n",
    "### Import models into hosting\n",
    "When creating the Model entity for multi-model endpoints, the container's `ModelDataUrl` is the S3 prefix where the model artifacts that are invokable by the endpoint are located. The rest of the S3 path will be specified when invoking the model.\n",
    "\n",
    "The `Mode` of container is specified as `MultiModel` to signify that the container will host multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: DEMO-MultiModelModel2020-06-02-02-09-11\n",
      "Model data Url: https://s3-us-east-1.amazonaws.com/sagemaker-us-east-1-111652037296/demo-multimodel-endpoint/\n",
      "Container image: 111652037296.dkr.ecr.us-east-1.amazonaws.com/demo-sagemaker-multimodel:latest\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:111652037296:model/demo-multimodelmodel2020-06-02-02-09-11\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = 'DEMO-MultiModelModel' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_url = 'https://s3-{}.amazonaws.com/{}/{}/'.format(region, bucket, prefix)\n",
    "container = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account_id, region, 'demo-sagemaker-multimodel')\n",
    "\n",
    "print('Model name: ' + model_name)\n",
    "print('Model data Url: ' + model_url)\n",
    "print('Container image: ' + container)\n",
    "\n",
    "container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_url,\n",
    "    'Mode': 'MultiModel'\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [container])\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "Endpoint config creation works the same way it does as single model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint config name: DEMO-MultiModelEndpointConfig-2020-06-02-02-09-11\n",
      "Endpoint config Arn: arn:aws:sagemaker:us-east-1:111652037296:endpoint-config/demo-multimodelendpointconfig-2020-06-02-02-09-11\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = 'DEMO-MultiModelEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Endpoint config name: ' + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': 'ml.m5.xlarge',\n",
    "        'InitialInstanceCount': 2,\n",
    "        'InitialVariantWeight': 1,\n",
    "        'ModelName': model_name,\n",
    "        'VariantName': 'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Similarly, endpoint creation works the same way as for single model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: DEMO-MultiModelEndpoint-2020-06-02-02-09-11\n",
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:111652037296:endpoint/demo-multimodelendpoint-2020-06-02-02-09-11\n",
      "Endpoint Status: Creating\n",
      "Waiting for DEMO-MultiModelEndpoint-2020-06-02-02-09-11 endpoint to be in service...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "endpoint_name = 'DEMO-MultiModelEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Endpoint name: ' + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print('Endpoint Arn: ' + create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print('Waiting for {} endpoint to be in service...'.format(endpoint_name))\n",
    "waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke models\n",
    "Now we invoke the models that we uploaded to S3 previously. The first invocation of a model may be slow, since behind the scenes, SageMaker is downloading the model artifacts from S3 to the instance and loading it into the container.\n",
    "\n",
    "First we will download an image of a cat as the payload to invoke the model, then call InvokeEndpoint to invoke the ResNet 18 model. The `TargetModel` field is concatenated with the S3 prefix specified in `ModelDataUrl` when creating the model, to generate the location of the model in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = mx.test_utils.download('https://github.com/dmlc/web-data/blob/master/mxnet/doc/tutorials/python/predict_image/cat.jpg?raw=true', 'cat.jpg')\n",
    "\n",
    "with open(fname, 'rb') as f:\n",
    "    payload = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability=0.244390, class=n02119022 red fox, Vulpes vulpes\n",
      "probability=0.170341, class=n02119789 kit fox, Vulpes macrotis\n",
      "probability=0.145019, class=n02113023 Pembroke, Pembroke Welsh corgi\n",
      "probability=0.059833, class=n02356798 fox squirrel, eastern fox squirrel, Sciurus niger\n",
      "probability=0.051555, class=n02123159 tiger cat\n",
      "CPU times: user 15.8 ms, sys: 0 ns, total: 15.8 ms\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    TargetModel='resnet_18.tar.gz', # this is the rest of the S3 path where the model artifacts are located\n",
    "    Body=payload)\n",
    "\n",
    "print(*json.loads(response['Body'].read()), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we invoke the same ResNet 18 model a 2nd time, it is already downloaded to the instance and loaded in the container, so inference is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability=0.244390, class=n02119022 red fox, Vulpes vulpes\n",
      "probability=0.170341, class=n02119789 kit fox, Vulpes macrotis\n",
      "probability=0.145019, class=n02113023 Pembroke, Pembroke Welsh corgi\n",
      "probability=0.059833, class=n02356798 fox squirrel, eastern fox squirrel, Sciurus niger\n",
      "probability=0.051555, class=n02123159 tiger cat\n",
      "CPU times: user 8.26 ms, sys: 106 µs, total: 8.37 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    TargetModel='resnet_18.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(*json.loads(response['Body'].read()), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke another model\n",
    "Exercising the power of a multi-model endpoint, we can specify a different model (resnet_152.tar.gz) as `TargetModel` and perform inference on it using the same endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability=0.386026, class=n02119022 red fox, Vulpes vulpes\n",
      "probability=0.300927, class=n02119789 kit fox, Vulpes macrotis\n",
      "probability=0.029575, class=n02123045 tabby, tabby cat\n",
      "probability=0.026005, class=n02123159 tiger cat\n",
      "probability=0.023201, class=n02113023 Pembroke, Pembroke Welsh corgi\n",
      "CPU times: user 8.97 ms, sys: 0 ns, total: 8.97 ms\n",
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    TargetModel='resnet_152.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(*json.loads(response['Body'].read()), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add models to the endpoint\n",
    "We can add more models to the endpoint without having to update the endpoint. Below we are adding a 3rd model, `squeezenet_v1.0`. To demonstrate hosting multiple models behind the endpoint, this model is duplicated 10 times with a slightly different name in S3. In a more realistic scenario, these could be 10 new different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.test_utils.download(model_path+'squeezenet/squeezenet_v1.0-0000.params', None, 'data/squeezenet_v1.0')\n",
    "mx.test_utils.download(model_path+'squeezenet/squeezenet_v1.0-symbol.json', None, 'data/squeezenet_v1.0')\n",
    "mx.test_utils.download(model_path+'synset.txt', None, 'data/squeezenet_v1.0')\n",
    "\n",
    "with open('data/squeezenet_v1.0/squeezenet_v1.0-shapes.json', 'w') as file:\n",
    "    file.write('[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]')\n",
    "    \n",
    "with tarfile.open('data/squeezenet_v1.0.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('data/squeezenet_v1.0', arcname='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 12\n",
      "Models: {'demo-subfolder/squeezenet_v1.0_8.tar.gz', 'demo-subfolder/squeezenet_v1.0_4.tar.gz', 'demo-subfolder/squeezenet_v1.0_3.tar.gz', 'demo-subfolder/squeezenet_v1.0_7.tar.gz', 'demo-subfolder/squeezenet_v1.0_6.tar.gz', 'demo-subfolder/squeezenet_v1.0_9.tar.gz', 'demo-subfolder/squeezenet_v1.0_0.tar.gz', 'resnet_18.tar.gz', 'demo-subfolder/squeezenet_v1.0_2.tar.gz', 'demo-subfolder/squeezenet_v1.0_5.tar.gz', 'demo-subfolder/squeezenet_v1.0_1.tar.gz', 'resnet_152.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "file = 'data/squeezenet_v1.0.tar.gz'\n",
    "\n",
    "for x in range(0, 10):\n",
    "    s3_file_name = 'demo-subfolder/squeezenet_v1.0_{}.tar.gz'.format(x)\n",
    "    key = os.path.join(prefix, s3_file_name)\n",
    "    with open(file, 'rb') as file_obj:\n",
    "        s3.Bucket(bucket).Object(key).upload_fileobj(file_obj)\n",
    "    models.add(s3_file_name)\n",
    "\n",
    "print('Number of models: {}'.format(len(models)))\n",
    "print('Models: {}'.format(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading the SqueezeNet models to S3, we will invoke the endpoint 100 times, randomly choosing from one of the 12 models behind the S3 prefix for each invocation, and keeping a count of the label with the highest probability on each invoke response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('probability=0.294885, class=n02326432 hare', 82)\n",
      "('probability=0.386026, class=n02119022 red fox, Vulpes vulpes', 10)\n",
      "('probability=0.244390, class=n02119022 red fox, Vulpes vulpes', 8)\n",
      "CPU times: user 386 ms, sys: 25.9 ms, total: 412 ms\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "results = defaultdict(int)\n",
    "\n",
    "for x in range(0, 100):\n",
    "    target_model = random.choice(tuple(models))\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/x-image',\n",
    "        TargetModel=target_model,\n",
    "        Body=payload)\n",
    "\n",
    "    results[json.loads(response['Body'].read())[0]] += 1\n",
    "    \n",
    "print(*results.items(), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointStatus = InService\n"
     ]
    }
   ],
   "source": [
    "sagemaker_client = boto3.Session().client(service_name='sagemaker') \n",
    "\n",
    "# get the status of the endpoint\n",
    "response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print('EndpointStatus = {}'.format(status))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'CreationTime': datetime.datetime(2020, 6, 2, 2, 9, 11, 996000, tzinfo=tzlocal()),\n",
      "    'EndpointArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint/demo-multimodelendpoint-2020-06-02-02-09-11',\n",
      "    'EndpointConfigName': 'DEMO-MultiModelEndpointConfig-2020-06-02-02-09-11',\n",
      "    'EndpointName': 'DEMO-MultiModelEndpoint-2020-06-02-02-09-11',\n",
      "    'EndpointStatus': 'InService',\n",
      "    'LastModifiedTime': datetime.datetime(2020, 6, 2, 2, 16, 29, 810000, tzinfo=tzlocal()),\n",
      "    'ProductionVariants': [   {   'CurrentInstanceCount': 2,\n",
      "                                  'CurrentWeight': 1.0,\n",
      "                                  'DeployedImages': [{...}],\n",
      "                                  'DesiredInstanceCount': 2,\n",
      "                                  'DesiredWeight': 1.0,\n",
      "                                  'VariantName': 'AllTraffic'}],\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '795',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '02:29:43 GMT',\n",
      "                                               'x-amzn-requestid': 'e1d84dbc-22ce-4484-ac10-8c22e014295e'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': 'e1d84dbc-22ce-4484-ac10-8c22e014295e',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=4)\n",
    "\n",
    "response = sagemaker_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '2',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '04:20:00 GMT',\n",
      "                                               'x-amzn-requestid': 'd230484c-cdc8-4a51-b0b2-2ed0400fde22'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': 'd230484c-cdc8-4a51-b0b2-2ed0400fde22',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('application-autoscaling')\n",
    "\n",
    "resource_id='endpoint/' + endpoint_name + '/variant/' + 'AllTraffic'\n",
    "\n",
    "response = client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=2\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'Alarms': [   {   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:111652037296:alarm:TargetTracking-endpoint/DEMO-MultiModelEndpoint-2020-06-02-02-09-11/variant/AllTraffic-AlarmHigh-5c0f8a4e-7791-4c22-b036-2556a6e2db78',\n",
      "                      'AlarmName': 'TargetTracking-endpoint/DEMO-MultiModelEndpoint-2020-06-02-02-09-11/variant/AllTraffic-AlarmHigh-5c0f8a4e-7791-4c22-b036-2556a6e2db78'},\n",
      "                  {   'AlarmARN': 'arn:aws:cloudwatch:us-east-1:111652037296:alarm:TargetTracking-endpoint/DEMO-MultiModelEndpoint-2020-06-02-02-09-11/variant/AllTraffic-AlarmLow-42684d93-0527-4f55-b5a6-0984b83eb22c',\n",
      "                      'AlarmName': 'TargetTracking-endpoint/DEMO-MultiModelEndpoint-2020-06-02-02-09-11/variant/AllTraffic-AlarmLow-42684d93-0527-4f55-b5a6-0984b83eb22c'}],\n",
      "    'PolicyARN': 'arn:aws:autoscaling:us-east-1:111652037296:scalingPolicy:413bd755-47dc-4922-95f3-a5e8aa9e070e:resource/sagemaker/endpoint/DEMO-MultiModelEndpoint-2020-06-02-02-09-11/variant/AllTraffic:policyName/DEMO-ScalingPolicy',\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '929',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '04:20:02 GMT',\n",
      "                                               'x-amzn-requestid': 'e66f83b5-b96b-40ce-b98d-2684eb94301f'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': 'e66f83b5-b96b-40ce-b98d-2684eb94301f',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = client.put_scaling_policy(\n",
    "    PolicyName='DEMO-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 1.0,\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance',\n",
    "        },\n",
    "        'ScaleInCooldown': 600,\n",
    "        'ScaleOutCooldown': 300\n",
    "    }\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'CreationTime': datetime.datetime(2020, 6, 2, 2, 9, 11, 996000, tzinfo=tzlocal()),\n",
      "    'EndpointArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint/demo-multimodelendpoint-2020-06-02-02-09-11',\n",
      "    'EndpointConfigName': 'DEMO-MultiModelEndpointConfig-2020-06-02-02-09-11',\n",
      "    'EndpointName': 'DEMO-MultiModelEndpoint-2020-06-02-02-09-11',\n",
      "    'EndpointStatus': 'InService',\n",
      "    'LastModifiedTime': datetime.datetime(2020, 6, 2, 2, 34, 33, 302000, tzinfo=tzlocal()),\n",
      "    'ProductionVariants': [   {   'CurrentInstanceCount': 3,\n",
      "                                  'CurrentWeight': 1.0,\n",
      "                                  'DeployedImages': [{...}],\n",
      "                                  'DesiredInstanceCount': 3,\n",
      "                                  'DesiredWeight': 1.0,\n",
      "                                  'VariantName': 'AllTraffic'}],\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '796',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '04:20:02 GMT',\n",
      "                                               'x-amzn-requestid': '2a6c7c8f-93a0-404d-828f-cbe8898dcf1b'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': '2a6c7c8f-93a0-404d-828f-cbe8898dcf1b',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '2',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '04:19:38 GMT',\n",
      "                                               'x-amzn-requestid': '2c3bd375-fcdc-4113-aa88-40690cef354b'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': '2c3bd375-fcdc-4113-aa88-40690cef354b',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = client.deregister_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount'\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'EndpointArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint/demo-multimodelendpoint-2020-06-02-02-09-11',\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '111',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '04:40:30 GMT',\n",
      "                                               'x-amzn-requestid': 'a1e77695-1cd5-4a9f-a2a7-f0eeef11ee36'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': 'a1e77695-1cd5-4a9f-a2a7-f0eeef11ee36',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'DesiredInstanceCount': 1\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'CreationTime': datetime.datetime(2020, 6, 2, 2, 9, 11, 996000, tzinfo=tzlocal()),\n",
      "    'EndpointArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint/demo-multimodelendpoint-2020-06-02-02-09-11',\n",
      "    'EndpointConfigName': 'DEMO-MultiModelEndpointConfig-2020-06-02-02-09-11',\n",
      "    'EndpointName': 'DEMO-MultiModelEndpoint-2020-06-02-02-09-11',\n",
      "    'EndpointStatus': 'Updating',\n",
      "    'LastModifiedTime': datetime.datetime(2020, 6, 2, 4, 40, 30, 337000, tzinfo=tzlocal()),\n",
      "    'ProductionVariants': [   {   'CurrentInstanceCount': 2,\n",
      "                                  'CurrentWeight': 1.0,\n",
      "                                  'DeployedImages': [{...}],\n",
      "                                  'DesiredInstanceCount': 1,\n",
      "                                  'DesiredWeight': 1.0,\n",
      "                                  'VariantName': 'AllTraffic'}],\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '795',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '04:40:33 GMT',\n",
      "                                               'x-amzn-requestid': '79687f35-fdfe-417e-ba80-e11f79a20456'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': '79687f35-fdfe-417e-ba80-e11f79a20456',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'EndpointArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint/demo-multimodelendpoint-2020-06-02-02-09-11',\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '111',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '04:54:25 GMT',\n",
      "                                               'x-amzn-requestid': '0eb099e9-a6e0-4f53-a45d-8a64358c75ee'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': '0eb099e9-a6e0-4f53-a45d-8a64358c75ee',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'DesiredInstanceCount': 5\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'CreationTime': datetime.datetime(2020, 6, 2, 2, 9, 11, 996000, tzinfo=tzlocal()),\n",
      "    'EndpointArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint/demo-multimodelendpoint-2020-06-02-02-09-11',\n",
      "    'EndpointConfigName': 'DEMO-MultiModelEndpointConfig-2020-06-02-02-09-11',\n",
      "    'EndpointName': 'DEMO-MultiModelEndpoint-2020-06-02-02-09-11',\n",
      "    'EndpointStatus': 'Updating',\n",
      "    'LastModifiedTime': datetime.datetime(2020, 6, 2, 4, 54, 26, 722000, tzinfo=tzlocal()),\n",
      "    'ProductionVariants': [   {   'CurrentInstanceCount': 1,\n",
      "                                  'CurrentWeight': 1.0,\n",
      "                                  'DeployedImages': [{...}],\n",
      "                                  'DesiredInstanceCount': 5,\n",
      "                                  'DesiredWeight': 1.0,\n",
      "                                  'VariantName': 'AllTraffic'}],\n",
      "    'ResponseMetadata': {   'HTTPHeaders': {   'content-length': '795',\n",
      "                                               'content-type': 'application/x-amz-json-1.1',\n",
      "                                               'date': 'Tue, 02 Jun 2020 '\n",
      "                                                       '04:54:27 GMT',\n",
      "                                               'x-amzn-requestid': 'fcf6e6c7-92f8-4ec4-bd87-1c238e83dea2'},\n",
      "                            'HTTPStatusCode': 200,\n",
      "                            'RequestId': 'fcf6e6c7-92f8-4ec4-bd87-1c238e83dea2',\n",
      "                            'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating a model\n",
    "To update a model, you would follow the same approach as above and add it as a new model. For example, if you have retrained the `resnet_18.tar.gz` model and wanted to start invoking it, you would upload the updated model artifacts behind the S3 prefix with a new name such as `resnet_18_v2.tar.gz`, and then change the `TargetModel` field to invoke `resnet_18_v2.tar.gz` instead of `resnet_18.tar.gz`. You do not want to overwrite the model artifacts in Amazon S3, because the old version of the model might still be loaded in the containers or on the storage volume of the instances on the endpoint. Invocations to the new model could then invoke the old version of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Delete the hosting resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "#sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "#sm_client.delete_model(ModelName=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
